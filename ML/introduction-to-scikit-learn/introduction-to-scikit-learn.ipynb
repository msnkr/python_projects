{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac711ea",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn library.\n",
    "\n",
    "What we're going to cover\n",
    "\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimator/algorithm for our problem\n",
    "3. Fit the model/algorithm and use it to make predictions on our data\n",
    "4. Evaluating a model\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0852501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listify the contents\n",
    "what_were_covering = [\n",
    "    \"0. An end-to-end Scikit-Learn workflow\",\n",
    "    \"1. Getting the data ready\",\n",
    "    \"2. Choose the right estimator/algorithm for our problems\",\n",
    "    \"3. Fit the model/algorithm and use it to make predictions on our data\",\n",
    "    \"4. Evaluating a model\",\n",
    "    \"5. Improve a model\",\n",
    "    \"6. Save and load a trained model\",\n",
    "    \"7. Putting it all together!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b97968",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27767b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the data ready\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (feautres matrix)\n",
    "X =  heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b57228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Choose the right model and hyperparameters\n",
    "# This is a classification problem because we want to determine if X = heart disease\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 90)\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09929b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "y_label = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c15758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the model on the training data and test data\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f735482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2804b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Improve a model\n",
    "# Try different amount of n_estimators\n",
    "\n",
    "np.random.seed(10)\n",
    "for i in range(10, 100, 10):\n",
    "    print(\"Trying model with {} estimators\".format(i))\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(\"Model accuracy on test set: {} %\".format(clf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random-forest-model1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75595ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"Random-forest-model1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c882191d",
   "metadata": {},
   "source": [
    "# Retry again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1576fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_data.drop(\"target\", axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06826cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_data[\"target\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70834df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb256b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41679019",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019738a3",
   "metadata": {},
   "source": [
    "# Retry again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv(\"heart-disease.csv\")\n",
    "X = heart_data.drop(\"target\", axis=1)\n",
    "y = heart_data[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d620f",
   "metadata": {},
   "source": [
    "# 1. Getting your data ready\n",
    "\n",
    "Three main things we have to do:\n",
    "    1. Split the data into features and labels (Usually \"X\" and \"y\")\n",
    "    2. Filling (also called imputing) or disregarding missing values\n",
    "    3. Converting non-numerical values into numerical values (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3296ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423570d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape # Important, make sure shapes match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ae67e",
   "metadata": {},
   "source": [
    "# 1.1 Make sure its all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ea2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc99c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into x and y\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10618ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = car_sales[\"Price\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train) # FIt on training data\n",
    "model.score(X_test, y_test) # Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d17d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "transformed_x = transformer.fit_transform(X)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_x).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0868db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "# dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6adbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try refit the model\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_x,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bfc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d572017",
   "metadata": {},
   "source": [
    "# 1.2 What if there were missing values?\n",
    "1. Fill them with some value (also known as imputation)\n",
    "2. Remove the samples with missing data altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import car sales missing data\n",
    "missing_data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "missing_data.head()\n",
    "missing_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ae0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = missing_data.drop(\"Price\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = missing_data[\"Price\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                 one_hot,\n",
    "                                 categorical_features)],\n",
    "                               remainder=\"passthrough\")\n",
    "\n",
    "transformed_x = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86567794",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf403f",
   "metadata": {},
   "source": [
    "#### Option 1: Fill missing  data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "missing_data[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Color\" column\n",
    "missing_data[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill missing \"Odometer (KM)\" with mean of Odometer\n",
    "missing_data[\"Odometer (KM)\"].fillna(missing_data[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column with the average of doors\n",
    "missing_data[\"Doors\"].value_counts()\n",
    "missing_data[\"Doors\"].fillna(4, inplace=True)\n",
    "\n",
    "# CHeck our dataframe again\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing price value\n",
    "missing_data.dropna(inplace=True)\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = missing_data.drop(\"Price\", axis=1)\n",
    "y = missing_data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b61768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                 one_hot,\n",
    "                                 categorical_features)],\n",
    "                               remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd642089",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6204027",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e143d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ade214",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529378dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d429a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885d0c6",
   "metadata": {},
   "source": [
    "# Try again making data numerical and running ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45702c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the data ready\n",
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "car_sales.head(), len(car_sales), car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ceed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa517b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                 one_hot,\n",
    "                                 feature_data)],\n",
    "                               remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "X_pd = pd.DataFrame(data=transformed_X)\n",
    "X_pd.head()\n",
    "# model = RandomForestRegressor()\n",
    "# transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699564eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pd, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2ebec",
   "metadata": {},
   "source": [
    "# Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0164847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a71418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data ready\n",
    "missing_data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "missing_data.head(), len(missing_data), missing_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9159d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIll missing data in \"Make\", \"Color\", \"Odometer\", \"Doors\" with \"missing\" and drop missing data in price\n",
    "# Make string data numerical\n",
    "\n",
    "missing_data[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "missing_data[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "missing_data[\"Odometer (KM)\"].fillna(missing_data[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "missing_data[\"Doors\"].fillna(4, inplace=True)\n",
    "\n",
    "missing_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that all missing data has been sorted. Sort the data into X and y\n",
    "X = missing_data.drop(\"Price\", axis=1)\n",
    "y = missing_data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868879a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbff91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the data into numerical data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "feature_data = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                 one_hot,\n",
    "                                 feature_data)],\n",
    "                               remainder=\"passthrough\",\n",
    "                               sparse_threshold=0)\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "X_pd = pd.DataFrame(transformed_X)\n",
    "X_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e629b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model. We are trying to get an estimate of price\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pd, y, test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the data\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 100, 25):\n",
    "    model = RandomForestRegressor(n_estimators=i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pd, y, test_size=0.2)\n",
    "    model.fit(X_train, y_train);\n",
    "    model.score(X_train, y_train)\n",
    "    print(\"Testing {} estimators: Result = {}\".format(i, model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9fe90",
   "metadata": {},
   "source": [
    "# Option 2. FIll missing values with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7521ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d72f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4143bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with no labeks\n",
    "missing_data.dropna(subset=[\"Price\"], inplace=True)\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9625ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = missing_data.drop(\"Price\", axis=1)\n",
    "y = missing_data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491aa80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with scikit-learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with missing and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_feature = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_feature = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (Something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_feature),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_feature)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd = pd.DataFrame(filled_X,\n",
    "                    columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "X_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert catagorical value to numerical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "cat_data = [\"Make\", \"Colour\", \"Doors\"]\n",
    "hot_one = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"hot_one\", hot_one, cat_data)],\n",
    "                                remainder=\"passthrough\",\n",
    "                               sparse_threshold=0)\n",
    "\n",
    "transform_X = transformer.fit_transform(X_pd)\n",
    "transform_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our data is numbers and filled (No missing values). Fit a model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transform_X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa824898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452803ab",
   "metadata": {},
   "source": [
    "# Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data ready\n",
    "# Import the data\n",
    "# Check for missing data\n",
    "# Make categorical data numerical\n",
    "# Choose the right model\n",
    "# fit the model\n",
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe77a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01572ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import the data\n",
    "missing_data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed76b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. check for missing data\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data with no labels\n",
    "missing_data.dropna(subset=[\"Price\"], inplace=True)\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = missing_data.drop(\"Price\", axis=1)\n",
    "y = missing_data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the missing data in X\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "\n",
    "cat_feature = [\"Make\", \"Colour\"]\n",
    "mean_feature = [\"Odometer (KM)\"]\n",
    "door_feature = [\"Doors\"]\n",
    "\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_feature),\n",
    "    (\"mean_imputer\", mean_imputer,mean_feature),\n",
    "    (\"door_imputer\", door_imputer, door_feature)])\n",
    "\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data back into a dataframe\n",
    "X_pd = pd.DataFrame(filled_X, columns=[\"Make\", \"Colour\", \"Odometer (KM)\", \"Doors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc50750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical data into numerical data\n",
    "\n",
    "categorical_data = [\"Make\", \"Colour\", \"Odometer (KM)\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_data)], remainder=\"passthrough\", sparse_threshold=0)\n",
    "\n",
    "transformed_X = transformer.fit_transform(X_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293391c",
   "metadata": {},
   "source": [
    "# Fixing missing values with scikit-learn the recommended way\n",
    "* Fill the missing data with the transformer on X_train and X_test for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38113557",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d65042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the data ready\n",
    "missing_data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b423999",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data with no labels\n",
    "missing_data.dropna(subset=[\"Price\"], inplace=True)\n",
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = missing_data.drop(\"Price\", axis=1)\n",
    "y = missing_data[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb66953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing values\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "\n",
    "cat_feat = [\"Make\", \"Colour\"]\n",
    "num_feat = [\"Odometer (KM)\"]\n",
    "door_feat = [\"Doors\"]\n",
    "\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_feat),\n",
    "    (\"num_imputer\", num_imputer, num_feat),\n",
    "    (\"door_imputer\", door_imputer, door_feat)\n",
    "], remainder=\"passthrough\", sparse_threshold=0)\n",
    "\n",
    "transformed_X_train = imputer.fit_transform(X_train)\n",
    "transformed_X_test = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7679ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put transformed data into a dataframe\n",
    "X_train_pd = pd.DataFrame(transformed_X_train, columns=[\"Make\", \"Colour\", \"Odometer (KM)\", \"Doors\"])\n",
    "X_test_pd = pd.DataFrame(transformed_X_test, columns=[\"Make\", \"Colour\", \"Odometer (KM)\", \"Doors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314dc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing data\n",
    "X_train_pd.isna().sum(), X_test_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ceee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_pd), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9daa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change X_train_pd and X_test_pd into numerical data\n",
    "one_hot = OneHotEncoder()\n",
    "cat_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, cat_features)], remainder=\"passthrough\", sparse_threshold=0)\n",
    "\n",
    "transformed_X_train = transformer.fit_transform(X_train_pd)\n",
    "transformed_X_test = transformer.fit_transform(X_test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3257671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(transformed_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d54d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96926cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9700c0",
   "metadata": {},
   "source": [
    "# 2. Choose the right estimator/algorithm for out problems\n",
    "Scikit-Learn uses estimator for another term for machine learning or algorithm\n",
    "\n",
    "* Classification - predicting whether a sample is one thing or another\n",
    "* Regression - predicting a number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf7c6c",
   "metadata": {},
   "source": [
    "## 2.1 picking a machine learning model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "boston = pd.read_csv(\"HousingData.csv\")\n",
    "boston[\"target\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47028109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples\n",
    "len(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d3a725",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boston' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create the data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X \u001b[38;5;241m=\u001b[39m boston\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m boston[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'boston' is not defined"
     ]
    }
   ],
   "source": [
    "# Lets try the ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston.drop(\"target\", axis=1)\n",
    "y = boston[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the ridge model\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the train data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the score of the ridge model on test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50cac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cali housing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "cali_data = fetch_california_housing()\n",
    "\n",
    "cali_df = pd.DataFrame(cali_data[\"data\"], columns=cali_data[\"feature_names\"])\n",
    "cali_df[\"target\"] = pd.Series(cali_data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c54483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6097712980505098"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort out the data\n",
    "X = cali_df.drop(\"target\", axis=1)\n",
    "y = cali_df[\"target\"]\n",
    "\n",
    "# Split the data in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit the model\n",
    "model = Ridge()\n",
    "\n",
    "# Check the score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check train score\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92bf3556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5913788537398925"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check test score\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca022f71",
   "metadata": {},
   "source": [
    "How do we improve this score?\n",
    "\n",
    "What if ridge isnt working\n",
    "\n",
    "Lets refer back tot the map... https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b2d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803771542847289"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it with the RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac9569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RandomForest did a better job\n",
    "# Use the machine learning map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c80641",
   "metadata": {},
   "source": [
    "# 2.2 Choosing an estimator for a classification problem\n",
    " * Refer to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7389bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an estimator for the heart disease csv\n",
    "# Get the data ready\n",
    "\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Choose the correct estimator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7549affd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885245901639344"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df59961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets compare to RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "round(model.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abddd93d",
   "metadata": {},
   "source": [
    "* You chose the model wrong. You had less than 100K samples\n",
    "* Use LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c68def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ac206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "round(clf.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0abfc",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "\n",
    "    1. If you have structured data, use ensamble methods\n",
    "    2. If you have unstructured data, use deeplearning or transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7303f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'what_were_covering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m what_were_covering\n",
      "\u001b[1;31mNameError\u001b[0m: name 'what_were_covering' is not defined"
     ]
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b10d12",
   "metadata": {},
   "source": [
    "# 3. Fit the model and our data and use it to make predictions\n",
    "\n",
    "## 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for:\n",
    "* \"X\" = features, feature variables, data\n",
    "* \"y\" = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d906c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the data (Training machine learning model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model (Use the patterns the model has learnt)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf4f7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1885996f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c80b9e",
   "metadata": {},
   "source": [
    "### 3.2 Make predictions using a machine learning \n",
    "\n",
    "2 ways to make predictions:\n",
    "\n",
    "    * 1. predict()\n",
    "    * 2. predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99fd3a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 7. 8. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use a trained model to make predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 7. 8. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Use a trained model to make predictions\n",
    "model.predict(np.array([1, 7, 8, 3, 4])) # This doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0692b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82698931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582b8f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c657e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conpare predictions to truth labels to evaluate the model\n",
    "y_preds = model.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa26265b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a40bf629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78253b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "179   57    1   0       150   276    0        0      112      1      0.6   \n",
      "228   59    1   3       170   288    0        0      159      0      0.2   \n",
      "111   57    1   2       150   126    1        1      173      0      0.2   \n",
      "246   56    0   0       134   409    0        0      150      1      1.9   \n",
      "60    71    0   2       110   265    1        0      130      0      0.0   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "249   69    1   2       140   254    0        0      146      0      2.0   \n",
      "104   50    1   2       129   196    0        1      163      0      0.0   \n",
      "300   68    1   0       144   193    1        1      141      0      3.4   \n",
      "193   60    1   0       145   282    0        0      142      1      2.8   \n",
      "184   50    1   0       150   243    0        0      128      0      2.6   \n",
      "\n",
      "     slope  ca  thal  \n",
      "179      1   1     1  \n",
      "228      1   0     3  \n",
      "111      2   1     3  \n",
      "246      1   2     3  \n",
      "60       2   1     2  \n",
      "..     ...  ..   ...  \n",
      "249      1   3     3  \n",
      "104      2   0     2  \n",
      "300      1   2     3  \n",
      "193      1   2     3  \n",
      "184      1   0     3  \n",
      "\n",
      "[61 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efcc1d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179    0\n",
      "228    0\n",
      "111    1\n",
      "246    0\n",
      "60     1\n",
      "      ..\n",
      "249    0\n",
      "104    1\n",
      "300    0\n",
      "193    0\n",
      "184    0\n",
      "Name: target, Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca5697",
   "metadata": {},
   "source": [
    "Make predictions withh \"predict_proba()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c25acb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba() returns probabilities of a classification label\n",
    "model.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5b64ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets predict() on the same data\n",
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46bbdee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    165\n",
       "0    138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "70ac855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target with cali housing model using regression\n",
    "# Setup your data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "cali = fetch_california_housing()\n",
    "\n",
    "cali_df = pd.DataFrame(cali[\"data\"], columns=cali[\"feature_names\"])\n",
    "cali_df[\"target\"] = pd.Series(cali[\"target\"])\n",
    "\n",
    "X = cali_df.drop(\"target\", axis=1)\n",
    "y = cali_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d62f477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8082849194024588"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the regression model with RandomForestRegressor\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05fa07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5514b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26123  , 1.42044  , 3.2745204, 1.81706  , 0.95867  , 2.2390801,\n",
       "       4.1035521, 1.3133   , 0.8679001, 1.90411  ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d70ccbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.297, 1.343, 3.125, ..., 2.143, 1.651, 0.615]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62f04bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32885292671996147"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df9d8a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997cfa8",
   "metadata": {},
   "source": [
    "# The lower the number, the better the prediction\n",
    "* Because cali_df == 4.526, mean_absolute_error is 0.32. \n",
    "* Meaning its 0.32 off on the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66bbbab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68b9b5",
   "metadata": {},
   "source": [
    "# 4. Evaluating a model\n",
    "\n",
    "Three ways to evaluate Scikit-Learn models/estimators\n",
    "1. Estimatore \"score\" method\n",
    "2. The \"scoring\" parameter\n",
    "3. Problem-specific metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32cf8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a224064",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1924df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 4.1 Evaluating a model with the score method\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942432a",
   "metadata": {},
   "source": [
    "Lets do the same but for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5076e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "ali_df = pd.DataFrame(cali[\"data\"], columns=cali[\"feature_names\"])\n",
    "cali_df[\"target\"] = pd.Series(cali[\"target\"])\n",
    "\n",
    "X = cali_df.drop(\"target\", axis=1)\n",
    "y = cali_df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2712f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd48ce0",
   "metadata": {},
   "source": [
    "### Evaluating a model with the \"scoring\" parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10936ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
